# better-vllm-api
openai server for vllm with ability to start and stop the engine, and change the model being served without restarting
